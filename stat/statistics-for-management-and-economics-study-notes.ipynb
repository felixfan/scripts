{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#1.-What-is-Statistics?\" data-toc-modified-id=\"1.-What-is-Statistics?-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>1. What is Statistics?</a></div><div class=\"lev1 toc-item\"><a href=\"#2.-Graphical-Descriptive-Techniques-I\" data-toc-modified-id=\"2.-Graphical-Descriptive-Techniques-I-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>2. Graphical Descriptive Techniques I</a></div><div class=\"lev2 toc-item\"><a href=\"#2.1-Types-of-Data-and-Information\" data-toc-modified-id=\"2.1-Types-of-Data-and-Information-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>2.1 Types of Data and Information</a></div><div class=\"lev2 toc-item\"><a href=\"#2.2-Describing-a-Set-of-Nominal-Data\" data-toc-modified-id=\"2.2-Describing-a-Set-of-Nominal-Data-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>2.2 Describing a Set of Nominal Data</a></div><div class=\"lev1 toc-item\"><a href=\"#3.-Graphical-Descriptive-Techniques-II\" data-toc-modified-id=\"3.-Graphical-Descriptive-Techniques-II-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>3. Graphical Descriptive Techniques II</a></div><div class=\"lev2 toc-item\"><a href=\"#3.1-Describing-a-Set-of-Interval-Data\" data-toc-modified-id=\"3.1-Describing-a-Set-of-Interval-Data-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>3.1 Describing a Set of Interval Data</a></div><div class=\"lev2 toc-item\"><a href=\"#3.1.1-Histogram\" data-toc-modified-id=\"3.1.1-Histogram-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>3.1.1 Histogram</a></div><div class=\"lev2 toc-item\"><a href=\"#3.1.1.1-Determining-the-Number-of-Class-Intervals\" data-toc-modified-id=\"3.1.1.1-Determining-the-Number-of-Class-Intervals-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>3.1.1.1 Determining the Number of Class Intervals</a></div><div class=\"lev2 toc-item\"><a href=\"#3.1.2-Stem-and-Leaf-Display\" data-toc-modified-id=\"3.1.2-Stem-and-Leaf-Display-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>3.1.2 Stem-and-Leaf Display</a></div><div class=\"lev2 toc-item\"><a href=\"#3.2-Describing-time-series-Data\" data-toc-modified-id=\"3.2-Describing-time-series-Data-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>3.2 Describing time-series Data</a></div><div class=\"lev2 toc-item\"><a href=\"#3.3-Describing-the-Relationship-between-Two-Interval-Data\" data-toc-modified-id=\"3.3-Describing-the-Relationship-between-Two-Interval-Data-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>3.3 Describing the Relationship between Two Interval Data</a></div><div class=\"lev1 toc-item\"><a href=\"#4.-Numerical-Descriptive-Techniques\" data-toc-modified-id=\"4.-Numerical-Descriptive-Techniques-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>4. Numerical Descriptive Techniques</a></div><div class=\"lev2 toc-item\"><a href=\"#4.1-Measure-of-Central-Location\" data-toc-modified-id=\"4.1-Measure-of-Central-Location-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>4.1 Measure of Central Location</a></div><div class=\"lev3 toc-item\"><a href=\"#4.1.1-Arithmetic-Mean\" data-toc-modified-id=\"4.1.1-Arithmetic-Mean-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>4.1.1 Arithmetic Mean</a></div><div class=\"lev3 toc-item\"><a href=\"#4.1.2-Median\" data-toc-modified-id=\"4.1.2-Median-4.1.2\"><span class=\"toc-item-num\">4.1.2&nbsp;&nbsp;</span>4.1.2 Median</a></div><div class=\"lev3 toc-item\"><a href=\"#4.1.3-Mode\" data-toc-modified-id=\"4.1.3-Mode-4.1.3\"><span class=\"toc-item-num\">4.1.3&nbsp;&nbsp;</span>4.1.3 Mode</a></div><div class=\"lev3 toc-item\"><a href=\"#4.1.4-Mean,-Median,-Mode:-Which-Is-Best?\" data-toc-modified-id=\"4.1.4-Mean,-Median,-Mode:-Which-Is-Best?-4.1.4\"><span class=\"toc-item-num\">4.1.4&nbsp;&nbsp;</span>4.1.4 Mean, Median, Mode: Which Is Best?</a></div><div class=\"lev3 toc-item\"><a href=\"#4.1.5-Geometric-mean\" data-toc-modified-id=\"4.1.5-Geometric-mean-4.1.5\"><span class=\"toc-item-num\">4.1.5&nbsp;&nbsp;</span>4.1.5 Geometric mean</a></div><div class=\"lev2 toc-item\"><a href=\"#4.2-Measures-of-Variability\" data-toc-modified-id=\"4.2-Measures-of-Variability-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>4.2 Measures of Variability</a></div><div class=\"lev3 toc-item\"><a href=\"#4.2.1-Range\" data-toc-modified-id=\"4.2.1-Range-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>4.2.1 Range</a></div><div class=\"lev3 toc-item\"><a href=\"#4.2.2-Variance\" data-toc-modified-id=\"4.2.2-Variance-4.2.2\"><span class=\"toc-item-num\">4.2.2&nbsp;&nbsp;</span>4.2.2 Variance</a></div><div class=\"lev3 toc-item\"><a href=\"#4.2.3-Standard-Deviation\" data-toc-modified-id=\"4.2.3-Standard-Deviation-4.2.3\"><span class=\"toc-item-num\">4.2.3&nbsp;&nbsp;</span>4.2.3 Standard Deviation</a></div><div class=\"lev3 toc-item\"><a href=\"#4.2.4-Chebysheff’s-Theorem\" data-toc-modified-id=\"4.2.4-Chebysheff’s-Theorem-4.2.4\"><span class=\"toc-item-num\">4.2.4&nbsp;&nbsp;</span>4.2.4 Chebysheff’s Theorem</a></div><div class=\"lev3 toc-item\"><a href=\"#4.2.5-Coefficient-of-Variation\" data-toc-modified-id=\"4.2.5-Coefficient-of-Variation-4.2.5\"><span class=\"toc-item-num\">4.2.5&nbsp;&nbsp;</span>4.2.5 Coefficient of Variation</a></div><div class=\"lev2 toc-item\"><a href=\"#4.3-Measures-of-Relative-Standing-and-Box-Plots\" data-toc-modified-id=\"4.3-Measures-of-Relative-Standing-and-Box-Plots-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>4.3 Measures of Relative Standing and Box Plots</a></div><div class=\"lev3 toc-item\"><a href=\"#4.3.1-Percentile\" data-toc-modified-id=\"4.3.1-Percentile-4.3.1\"><span class=\"toc-item-num\">4.3.1&nbsp;&nbsp;</span>4.3.1 Percentile</a></div><div class=\"lev3 toc-item\"><a href=\"#4.3.2-Locating-Percentiles\" data-toc-modified-id=\"4.3.2-Locating-Percentiles-4.3.2\"><span class=\"toc-item-num\">4.3.2&nbsp;&nbsp;</span>4.3.2 Locating Percentiles</a></div><div class=\"lev3 toc-item\"><a href=\"#4.3.3-Interquartile-Range\" data-toc-modified-id=\"4.3.3-Interquartile-Range-4.3.3\"><span class=\"toc-item-num\">4.3.3&nbsp;&nbsp;</span>4.3.3 Interquartile Range</a></div><div class=\"lev3 toc-item\"><a href=\"#4.3.4-Box-Plots\" data-toc-modified-id=\"4.3.4-Box-Plots-4.3.4\"><span class=\"toc-item-num\">4.3.4&nbsp;&nbsp;</span>4.3.4 Box Plots</a></div><div class=\"lev2 toc-item\"><a href=\"#4.4-Measures-of-Linear-Relationship\" data-toc-modified-id=\"4.4-Measures-of-Linear-Relationship-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>4.4 Measures of Linear Relationship</a></div><div class=\"lev3 toc-item\"><a href=\"#4.4.1-Covariance\" data-toc-modified-id=\"4.4.1-Covariance-4.4.1\"><span class=\"toc-item-num\">4.4.1&nbsp;&nbsp;</span>4.4.1 Covariance</a></div><div class=\"lev3 toc-item\"><a href=\"#4.4.2-Coefficient-of-Correlation\" data-toc-modified-id=\"4.4.2-Coefficient-of-Correlation-4.4.2\"><span class=\"toc-item-num\">4.4.2&nbsp;&nbsp;</span>4.4.2 Coefficient of Correlation</a></div><div class=\"lev3 toc-item\"><a href=\"#4.4.3-Least-Squares-Method\" data-toc-modified-id=\"4.4.3-Least-Squares-Method-4.4.3\"><span class=\"toc-item-num\">4.4.3&nbsp;&nbsp;</span>4.4.3 Least Squares Method</a></div><div class=\"lev3 toc-item\"><a href=\"#4.4.4-Coefficient-of-Determination\" data-toc-modified-id=\"4.4.4-Coefficient-of-Determination-4.4.4\"><span class=\"toc-item-num\">4.4.4&nbsp;&nbsp;</span>4.4.4 Coefficient of Determination</a></div><div class=\"lev3 toc-item\"><a href=\"#4.4.5-Interpreting-Correlation\" data-toc-modified-id=\"4.4.5-Interpreting-Correlation-4.4.5\"><span class=\"toc-item-num\">4.4.5&nbsp;&nbsp;</span>4.4.5 Interpreting Correlation</a></div><div class=\"lev1 toc-item\"><a href=\"#5.-Data-Collection-And-Sampling\" data-toc-modified-id=\"5.-Data-Collection-And-Sampling-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>5. Data Collection And Sampling</a></div><div class=\"lev2 toc-item\"><a href=\"#5.1-Simple-Random-Sample\" data-toc-modified-id=\"5.1-Simple-Random-Sample-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>5.1 Simple Random Sample</a></div><div class=\"lev2 toc-item\"><a href=\"#5.2-Stratified-Random-Sampling\" data-toc-modified-id=\"5.2-Stratified-Random-Sampling-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>5.2 Stratified Random Sampling</a></div><div class=\"lev2 toc-item\"><a href=\"#5.3-Cluster-Sampling\" data-toc-modified-id=\"5.3-Cluster-Sampling-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>5.3 Cluster Sampling</a></div><div class=\"lev2 toc-item\"><a href=\"#5.4-Sampling-Error\" data-toc-modified-id=\"5.4-Sampling-Error-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>5.4 Sampling Error</a></div><div class=\"lev2 toc-item\"><a href=\"#5.5-Nonsampling-Error\" data-toc-modified-id=\"5.5-Nonsampling-Error-5.5\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;</span>5.5 Nonsampling Error</a></div><div class=\"lev1 toc-item\"><a href=\"#6-Probability\" data-toc-modified-id=\"6-Probability-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>6 Probability</a></div><div class=\"lev2 toc-item\"><a href=\"#6.1-Intersection\" data-toc-modified-id=\"6.1-Intersection-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>6.1 Intersection</a></div><div class=\"lev2 toc-item\"><a href=\"#6.2-Marginal-Probability\" data-toc-modified-id=\"6.2-Marginal-Probability-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>6.2 Marginal Probability</a></div><div class=\"lev2 toc-item\"><a href=\"#6.3-Conditional-Probability\" data-toc-modified-id=\"6.3-Conditional-Probability-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>6.3 Conditional Probability</a></div><div class=\"lev2 toc-item\"><a href=\"#6.4-Independence\" data-toc-modified-id=\"6.4-Independence-6.4\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;</span>6.4 Independence</a></div><div class=\"lev2 toc-item\"><a href=\"#6.5-Union\" data-toc-modified-id=\"6.5-Union-6.5\"><span class=\"toc-item-num\">6.5&nbsp;&nbsp;</span>6.5 Union</a></div><div class=\"lev2 toc-item\"><a href=\"#6.6-Complement-Rule\" data-toc-modified-id=\"6.6-Complement-Rule-6.6\"><span class=\"toc-item-num\">6.6&nbsp;&nbsp;</span>6.6 Complement Rule</a></div><div class=\"lev2 toc-item\"><a href=\"#6.7-Multiplication-Rule\" data-toc-modified-id=\"6.7-Multiplication-Rule-6.7\"><span class=\"toc-item-num\">6.7&nbsp;&nbsp;</span>6.7 Multiplication Rule</a></div><div class=\"lev2 toc-item\"><a href=\"#6.8-Addition-Rule\" data-toc-modified-id=\"6.8-Addition-Rule-6.8\"><span class=\"toc-item-num\">6.8&nbsp;&nbsp;</span>6.8 Addition Rule</a></div><div class=\"lev2 toc-item\"><a href=\"#6.9-Bayes’s-Law-Formula\" data-toc-modified-id=\"6.9-Bayes’s-Law-Formula-6.9\"><span class=\"toc-item-num\">6.9&nbsp;&nbsp;</span>6.9 Bayes’s Law Formula</a></div><div class=\"lev1 toc-item\"><a href=\"#7.-Random-Variables-and-Discrete-Probability-Distributions\" data-toc-modified-id=\"7.-Random-Variables-and-Discrete-Probability-Distributions-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>7. Random Variables and Discrete Probability Distributions</a></div><div class=\"lev2 toc-item\"><a href=\"#7.1-Describing-the-Population-Probability-Distribution\" data-toc-modified-id=\"7.1-Describing-the-Population-Probability-Distribution-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>7.1 Describing the Population Probability Distribution</a></div><div class=\"lev2 toc-item\"><a href=\"#7.2-Laws-of-Expected-Value-and-Variance\" data-toc-modified-id=\"7.2-Laws-of-Expected-Value-and-Variance-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>7.2 Laws of Expected Value and Variance</a></div><div class=\"lev2 toc-item\"><a href=\"#7.3-Bivariate-Distributions\" data-toc-modified-id=\"7.3-Bivariate-Distributions-7.3\"><span class=\"toc-item-num\">7.3&nbsp;&nbsp;</span>7.3 Bivariate Distributions</a></div><div class=\"lev2 toc-item\"><a href=\"#7.4-Laws-of-Expected-Value-and-Variance-of-the-Sum-of-Two-Variables\" data-toc-modified-id=\"7.4-Laws-of-Expected-Value-and-Variance-of-the-Sum-of-Two-Variables-7.4\"><span class=\"toc-item-num\">7.4&nbsp;&nbsp;</span>7.4 Laws of Expected Value and Variance of the Sum of Two Variables</a></div><div class=\"lev2 toc-item\"><a href=\"#7.5-Mean-and-Variance-of-a-Portfolio-of-Two-Stocks\" data-toc-modified-id=\"7.5-Mean-and-Variance-of-a-Portfolio-of-Two-Stocks-7.5\"><span class=\"toc-item-num\">7.5&nbsp;&nbsp;</span>7.5 Mean and Variance of a Portfolio of Two Stocks</a></div><div class=\"lev2 toc-item\"><a href=\"#7.6-Portfolios-with-More-Than-Two-Stocks\" data-toc-modified-id=\"7.6-Portfolios-with-More-Than-Two-Stocks-7.6\"><span class=\"toc-item-num\">7.6&nbsp;&nbsp;</span>7.6 Portfolios with More Than Two Stocks</a></div><div class=\"lev2 toc-item\"><a href=\"#7.7-Binormial-Distribution\" data-toc-modified-id=\"7.7-Binormial-Distribution-7.7\"><span class=\"toc-item-num\">7.7&nbsp;&nbsp;</span>7.7 Binormial Distribution</a></div><div class=\"lev3 toc-item\"><a href=\"#7.7.1-Cumulative-Probability\" data-toc-modified-id=\"7.7.1-Cumulative-Probability-7.7.1\"><span class=\"toc-item-num\">7.7.1&nbsp;&nbsp;</span>7.7.1 Cumulative Probability</a></div><div class=\"lev3 toc-item\"><a href=\"#7.7.2-Binomial-Probability-p(X-≥-x)\" data-toc-modified-id=\"7.7.2-Binomial-Probability-p(X-≥-x)-7.7.2\"><span class=\"toc-item-num\">7.7.2&nbsp;&nbsp;</span>7.7.2 Binomial Probability p(X ≥ x)</a></div><div class=\"lev3 toc-item\"><a href=\"#7.7.3-Binomial-Probability-P(X-=-x)\" data-toc-modified-id=\"7.7.3-Binomial-Probability-P(X-=-x)-7.7.3\"><span class=\"toc-item-num\">7.7.3&nbsp;&nbsp;</span>7.7.3 Binomial Probability P(X = x)</a></div><div class=\"lev3 toc-item\"><a href=\"#7.7.4-Mean-and-Variance-of-a-Binomial-Distribution\" data-toc-modified-id=\"7.7.4-Mean-and-Variance-of-a-Binomial-Distribution-7.7.4\"><span class=\"toc-item-num\">7.7.4&nbsp;&nbsp;</span>7.7.4 Mean and Variance of a Binomial Distribution</a></div><div class=\"lev2 toc-item\"><a href=\"#7.8-Poisson-Distribution\" data-toc-modified-id=\"7.8-Poisson-Distribution-7.8\"><span class=\"toc-item-num\">7.8&nbsp;&nbsp;</span>7.8 Poisson Distribution</a></div><div class=\"lev1 toc-item\"><a href=\"#8.-Continuous-Probability-Distributions\" data-toc-modified-id=\"8.-Continuous-Probability-Distributions-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>8. Continuous Probability Distributions</a></div><div class=\"lev2 toc-item\"><a href=\"#8.1-Uniform-Distribution\" data-toc-modified-id=\"8.1-Uniform-Distribution-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>8.1 Uniform Distribution</a></div><div class=\"lev2 toc-item\"><a href=\"#8.2-Normal-Distribution\" data-toc-modified-id=\"8.2-Normal-Distribution-8.2\"><span class=\"toc-item-num\">8.2&nbsp;&nbsp;</span>8.2 Normal Distribution</a></div><div class=\"lev3 toc-item\"><a href=\"#8.2.1-Calculating-Normal-Probabilities\" data-toc-modified-id=\"8.2.1-Calculating-Normal-Probabilities-8.2.1\"><span class=\"toc-item-num\">8.2.1&nbsp;&nbsp;</span>8.2.1 Calculating Normal Probabilities</a></div><div class=\"lev2 toc-item\"><a href=\"#8.3-Exponential-Distribution\" data-toc-modified-id=\"8.3-Exponential-Distribution-8.3\"><span class=\"toc-item-num\">8.3&nbsp;&nbsp;</span>8.3 Exponential Distribution</a></div><div class=\"lev2 toc-item\"><a href=\"#8.4-Student-t-Distribution\" data-toc-modified-id=\"8.4-Student-t-Distribution-8.4\"><span class=\"toc-item-num\">8.4&nbsp;&nbsp;</span>8.4 Student t Distribution</a></div><div class=\"lev2 toc-item\"><a href=\"#8.5-Chi-Squared-Distribution\" data-toc-modified-id=\"8.5-Chi-Squared-Distribution-8.5\"><span class=\"toc-item-num\">8.5&nbsp;&nbsp;</span>8.5 Chi-Squared Distribution</a></div><div class=\"lev2 toc-item\"><a href=\"#8.6-F-Distribution\" data-toc-modified-id=\"8.6-F-Distribution-8.6\"><span class=\"toc-item-num\">8.6&nbsp;&nbsp;</span>8.6 F Distribution</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. What is Statistics?\n",
    "\n",
    "- **population** is the group of all items of interest to a statistics practitioner. A descriptive measure of a population is called a **parameter**.\n",
    "- **sample** is a set of data drawn from the studied population. A descriptive measure of a sample is called a **statistic**.   \n",
    "\n",
    "# 2. Graphical Descriptive Techniques I\n",
    "\n",
    "## 2.1 Types of Data and Information\n",
    "\n",
    "- **Interval data** are real numbers, such as heights, weights, incomes, and distances. We also refer to this type of data as **quantitative** or **numerical**.\n",
    "- The values of **nominal data** are categories. the values are not numbers but instead are words that describe the categories. Nominal data are also called **qualitative** or **categorical**.\n",
    "- **Ordinal data** appear to be nominal, but the difference is that the order of their values has meaning.\n",
    "\n",
    "## 2.2 Describing a Set of Nominal Data\n",
    "\n",
    "- A **bar chart** is often used to display frequencies; \n",
    "- A **pie chart** graphically shows relative frequencies.\n",
    "- The bar chart focuses on the frequencies and the pie chart focuses on the proportions\n",
    "\n",
    "# 3. Graphical Descriptive Techniques II\n",
    "\n",
    "## 3.1 Describing a Set of Interval Data\n",
    "\n",
    "## 3.1.1 Histogram\n",
    "\n",
    "A **histogram** is created by drawing rectangles whose bases are the intervals and whose heights are the frequencies.\n",
    "\n",
    "## 3.1.1.1 Determining the Number of Class Intervals\n",
    "\n",
    "$$Number\\ Of\\ Class\\ Intervals = 1 + 3.3 log(n)$$ \n",
    "\n",
    "\n",
    "$$Class\\ Width = \\frac{Largest\\ Observation - Smallest\\ Observation}{Number\\ Of\\ Classes}$$\n",
    "\n",
    "## 3.1.2 Stem-and-Leaf Display\n",
    "\n",
    "The first step in developing a stem-and-leaf display is to split each observation into two parts, a stem and a leaf. There are several different ways of doing this. For example, the number 12.3 can be split so that the stem is 12 and the leaf is 3. Another method can define the stem as 1 and the leaf as 2 (ignoring the 3). After each stem, we list that stem’s leaves, usually in ascending order. The advantage of the stem-and-leaf display over the histogram is that we can see the\n",
    "actual observations.\n",
    "\n",
    "```\n",
    "Stem  Leaf\n",
    "0     000000000111112222223333345555556666666778888999999\n",
    "1     000001111233333334455555667889999\n",
    "2     0000111112344666778999\n",
    "3     001335589\n",
    "4     124445589\n",
    "5     022224556789\n",
    "```\n",
    "\n",
    "## 3.2 Describing time-series Data\n",
    "\n",
    "**cross-sectional data** classifies data by type, **time-series data** classifies them according to whether the observations are measured at the same time or whether they represent measurements at successive points in time. Time-series data are often graphically depicted on a **line chart**, which plots the value of the variable on the vertical axis and the time periods on the horizontal axis.    \n",
    "\n",
    "## 3.3 Describing the Relationship between Two Interval Data\n",
    "\n",
    "In applications where one variable depends to some degree on the other variable, we label the dependent\n",
    "variable Y and the other, called the independent variable, X. In interpreting the results of a scatter diagram it is important to understand that if two variables are linearly related it does not mean that one is causing the other. **Correlation is not causation**.\n",
    "\n",
    "# 4. Numerical Descriptive Techniques\n",
    "\n",
    "## 4.1 Measure of Central Location\n",
    "\n",
    "### 4.1.1 Arithmetic Mean\n",
    "\n",
    "$$\\mu=\\frac{\\sum_{i=1}^Nx_{i}}{N}$$\n",
    "\n",
    "$$\\bar x=\\frac{\\sum_{i=1}^nx_{i}}{n}$$\n",
    "\n",
    "### 4.1.2 Median\n",
    "\n",
    "The median is calculated by placing all the observations in order (ascending or descending). The observation that falls in the middle is the median. When there is an even number of observations, the median is determined by averaging the two observations in the middle.\n",
    "\n",
    "### 4.1.3 Mode\n",
    "\n",
    "The mode is defined as the observation (or observations) that occurs with the greatest frequency.\n",
    "\n",
    "### 4.1.4 Mean, Median, Mode: Which Is Best?\n",
    "\n",
    "The mean is generally our first selection. One advantage the median holds is that it is not as sensitive to extreme values as is the mean. The mode is seldom the best measure of central location.\n",
    "\n",
    "### 4.1.5 Geometric mean\n",
    "\n",
    "$$(1+R_{g})^n=(1+R_{1})(1+R_{2})\\cdots(1+R{n})$$\n",
    "\n",
    "## 4.2 Measures of Variability\n",
    "\n",
    "### 4.2.1 Range\n",
    "\n",
    "```\n",
    "Range = Largest observation − Smallest observation\n",
    "```\n",
    "\n",
    "### 4.2.2 Variance\n",
    "\n",
    "$$\\sigma^2=\\frac{\\sum_{i=1}^N(x_{i}-\\mu)^2}{N}$$\n",
    "\n",
    "$$s^2=\\frac{\\sum_{i=1}^n(x_{i}-\\bar x)^2}{n-1}$$\n",
    "\n",
    "### 4.2.3 Standard Deviation\n",
    "\n",
    "$$\\sigma = \\sqrt{\\sigma ^2}$$\n",
    "$$s = \\sqrt{s ^2}$$\n",
    "\n",
    "### 4.2.4 Chebysheff’s Theorem\n",
    "\n",
    "The proportion of observations in any sample or population that lie within k standard deviations of the mean is at least\n",
    "\n",
    "$$1 - \\frac{1}{k^2}, k>1$$\n",
    "\n",
    "### 4.2.5 Coefficient of Variation\n",
    "\n",
    "$$CV = \\frac{\\sigma}{\\mu}$$\n",
    "\n",
    "$$cv = \\frac{s}{\\bar x}$$\n",
    "\n",
    "## 4.3 Measures of Relative Standing and Box Plots\n",
    "\n",
    "### 4.3.1 Percentile\n",
    "\n",
    "The $P_{th}$ percentile is the value for which P percent are less than that value and (100 – P)% are greater than that value.\n",
    "\n",
    "### 4.3.2 Locating Percentiles\n",
    "\n",
    "$$L_{p} = (n+1)\\frac{P}{100}$$\n",
    "\n",
    "where $L_{p}$ is the location of the $P_{th}$ percentile.        \n",
    "\n",
    "Placing the 10 observations in ascending order we get\n",
    "\n",
    "```\n",
    "0 0 5 7 8 9 12 14 22 33\n",
    "```\n",
    "\n",
    "The location of the 25th percentile is   \n",
    "\n",
    "$$L_{25} = (10+1)\\frac{25}{100} = 2.75$$\n",
    "\n",
    "The $25_{th}$ percentile is three-quarters of the distance between the second (which is 0) and the third (which is 5) observations. Three-quarters of the distance is\n",
    "\n",
    "```\n",
    "(.75)(5 − 0) = 3.75\n",
    "```\n",
    "\n",
    "Because the second observation is 0, the $25_{th}$ percentile is 0 + 3.75 = 3.75.\n",
    "\n",
    "### 4.3.3 Interquartile Range\n",
    "\n",
    "$$Interquartile\\ Range = Q_{3} − Q_{1}$$\n",
    "\n",
    "### 4.3.4 Box Plots\n",
    "\n",
    "This technique graphs five statistics: the minimum and maximum observations, and the first, second, and third quartiles. The three vertical lines of the box are the first, second, and third quartiles. The lines extending to the left and right are called **whiskers**. Any points that lie outside the whiskers are called **outliers**. The whiskers extend outward to the smaller of 1.5 times the interquartile range or to the most extreme point that is not an outlier.\n",
    "\n",
    "## 4.4 Measures of Linear Relationship\n",
    "\n",
    "### 4.4.1 Covariance\n",
    "\n",
    "$$\\sigma_{xy} = \\frac{\\sum_{i=1}^N(x_{i}-\\mu_{x})(y_{i}-\\mu_{y})}{N}$$\n",
    "\n",
    "$$s_{xy} = \\frac{\\sum_{i=1}^n(x_{i}-\\bar x)(y_{i}-\\bar y)}{n-1}$$\n",
    "\n",
    "### 4.4.2 Coefficient of Correlation\n",
    "\n",
    "$$\\rho=\\frac{\\sigma_{xy}}{\\sigma_{x}\\sigma_{y}}$$\n",
    "\n",
    "$$r=\\frac{s_{xy}}{s_{x}s_{y}}$$\n",
    "\n",
    "### 4.4.3 Least Squares Method\n",
    "\n",
    "$$\\hat y = b_{0} + b_{1}x$$\n",
    "\n",
    "The coefficients $b_{0}$ and $b_{1}$ are derived using calculus so that we minimize the sum of squared deviations:\n",
    "\n",
    "$$\\sum_{i=1}^n(y_{i}-\\hat{y_{i}})^2$$\n",
    "\n",
    "Least Squares Line Coefficients:   \n",
    "\n",
    "$$b_{1} = \\frac{s_{xy}}{s_{x}^2}$$\n",
    "$$b_{0} = \\bar y - b_{1}\\bar x$$\n",
    "\n",
    "### 4.4.4 Coefficient of Determination\n",
    "\n",
    "Coefficient of determination $R^2$ is calculated by squaring the coefficient of correlation. The coefficient of determination measures the amount of variation in the dependent variable that is explained by the variation in the independent variable.\n",
    "\n",
    "### 4.4.5 Interpreting Correlation\n",
    "\n",
    "**Correlation is not Causation**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 5. Data Collection And Sampling\n",
    "\n",
    "## 5.1 Simple Random Sample\n",
    "\n",
    "A simple random sample is a sample selected in such a way that every possible sample with the same number of observations is equally likely to be chosen.\n",
    "\n",
    "## 5.2 Stratified Random Sampling\n",
    "\n",
    "A stratified random sample is obtained by separating the population into mutually exclusive sets, or strata, and then drawing simple random samples from each stratum.\n",
    "\n",
    "## 5.3 Cluster Sampling\n",
    "\n",
    "A cluster sample is a simple random sample of groups or clusters of elements.\n",
    "\n",
    "## 5.4 Sampling Error\n",
    "\n",
    "Sampling error refers to differences between the sample and the population that exists only because of the observations that happened to be selected for the sample.\n",
    "\n",
    "## 5.5 Nonsampling Error\n",
    "\n",
    "Nonsampling errors result from mistakes made in the acquisition of data or from the sample observations being selected improperly.\n",
    "\n",
    "- Errors in data acquisition.\n",
    "- Nonresponse error refers to error (or bias) introduced when responses are not obtained from some members of the sample.\n",
    "- Selection bias occurs when the sampling plan is such that some members of the target population cannot possibly be selected for inclusion in the sample.\n",
    "\n",
    "# 6 Probability\n",
    "\n",
    "## 6.1 Intersection\n",
    "\n",
    "The intersection of events A and B is the event that occurs when both A and B occur. The probability of the intersection is called the **joint probability**.\n",
    "\n",
    "## 6.2 Marginal Probability\n",
    "\n",
    "Marginal probabilities, computed by adding across rows or down columns, are so named because they are calculated in the margins of the table.   \n",
    "\n",
    "## 6.3 Conditional Probability\n",
    "\n",
    "The probability of event A given event B is\n",
    "\n",
    "$$p(A|B) = \\frac{p(AB)}{p(B)}$$\n",
    "\n",
    "The probability of event B given event A is\n",
    "\n",
    "$$p(B|A) = \\frac{p(AB)}{p(A)}$$\n",
    "\n",
    "## 6.4 Independence\n",
    "\n",
    "Two events A and B are said to be independent if\n",
    "\n",
    "$$p(A|B) = p(A)$$\n",
    "\n",
    "or\n",
    "\n",
    "$$p(B|A) = p(B)$$\n",
    "\n",
    "## 6.5 Union\n",
    "\n",
    "The union of events A and B is the event that occurs when either A or B or both occur. It is denoted as\n",
    "`A or B`.\n",
    "\n",
    "## 6.6 Complement Rule\n",
    "\n",
    "The complement of event A is the event that occurs when event A does not occur.\n",
    "\n",
    "$$p(A^c) = 1 - p(A)$$\n",
    "\n",
    "## 6.7 Multiplication Rule\n",
    "\n",
    "$$p(AB) = p(A)p(B|A) = p(B)p(A|B)$$\n",
    "\n",
    "## 6.8 Addition Rule\n",
    "\n",
    "The probability that event A, or event B, or both occur is\n",
    "\n",
    "$$p(A or B) = p(A) + p(B) - p(AB)$$\n",
    "\n",
    "## 6.9 Bayes’s Law Formula\n",
    "\n",
    "$$p(A_{i}|B) = \\frac{p(A_{i})p(B|A_{i})}{p(A_{1})p(B|A_{1}) + p(A_{2})p(B|A_{2}) + \\cdots + p(A_{k})p(B|A_{k})}$$\n",
    "\n",
    "# 7. Random Variables and Discrete Probability Distributions\n",
    "\n",
    "## 7.1 Describing the Population Probability Distribution\n",
    "\n",
    "$$E(x) = \\mu = \\sum xp(x)$$\n",
    "\n",
    "$$V(x) = \\sigma^2 = \\sum (x-\\mu)^2p(x)$$\n",
    "\n",
    "## 7.2 Laws of Expected Value and Variance\n",
    "\n",
    "$$E(c) = c$$\n",
    "$$E(x + c) = E(x) + c$$\n",
    "$$E(cx) = cE(x)$$\n",
    "$$V(c) = 0$$\n",
    "$$V(x + c) = V(x)$$\n",
    "$$V(cx) = c^2V(x)$$\n",
    "\n",
    "## 7.3 Bivariate Distributions\n",
    "\n",
    "The covariance of two discrete variables is defined as\n",
    "\n",
    "$$COV(x, y) = \\sigma_{xy} = \\sum \\sum (x - \\mu_{x})(y-\\mu_{y})p(x, y)$$\n",
    "\n",
    "Coefficient of Correlation:\n",
    "\n",
    "$$\\rho = \\frac{\\sigma_{xy}}{\\sigma_{x}\\sigma_{y}}$$\n",
    "\n",
    "## 7.4 Laws of Expected Value and Variance of the Sum of Two Variables\n",
    "\n",
    "$$E(x + y) = E(x) + E(y)$$\n",
    "\n",
    "$$V(x + y) = V(x) + V(y) + 2COV(x + y)$$\n",
    "\n",
    "## 7.5 Mean and Variance of a Portfolio of Two Stocks\n",
    "\n",
    "$$E(R_{p}) = w_{1}E(R_{1}) + w_{2}E(R_{2})$$\n",
    "\n",
    "$$V(R_{p}) = w_{1}^2V(R_{1}) + w_{2}^2V(R_{2}) + 2w_{1}w_{2}COV(R_{1}, R_{2}) = w_{1}^2V(R_{1}) + w_{2}^2V(R_{2}) + 2w_{1}w_{2}\\rho\\sigma_{1}\\sigma_{2}$$\n",
    "\n",
    "## 7.6 Portfolios with More Than Two Stocks\n",
    "\n",
    "$$E(R_{p}) = \\sum_{i=1}^k w_{i}E(R_{i})$$\n",
    "\n",
    "$$V(R_{p}) = \\sum_{i=1}^k w_{i}^2V(R_{i}) + 2\\sum_{i=1}^k \\sum_{j=i+1}^k w_{i}w_{j}COV(R_{i}, R_{j})$$\n",
    "\n",
    "## 7.7 Binormial Distribution\n",
    "\n",
    "- The binomial experiment consists of a fixed number of trials (n).\n",
    "- Each trial has two possible outcomes. success or failure.\n",
    "- The probability of success is p. The probability of failure is 1 − p.\n",
    "- The trials are independent\n",
    "\n",
    "The probability of x successes in a binomial experiment with n trials and probability of success = p is\n",
    "\n",
    "$$p(x) = \\frac{n!}{x!(n-x)!}p^x(1-p)^{n-x}$$\n",
    "\n",
    "### 7.7.1 Cumulative Probability\n",
    "\n",
    "$$p(X \\le 4) = p(0) + p(1) + p(2) + p(3) + p(4)$$\n",
    "\n",
    "### 7.7.2 Binomial Probability p(X ≥ x)\n",
    "\n",
    "$$p(X \\ge x) = 1 - p(X \\le (x-1))$$\n",
    "\n",
    "### 7.7.3 Binomial Probability P(X = x)\n",
    "\n",
    "$$p(x) = p(X \\le x) - p(X \\le (x-1))$$\n",
    "\n",
    "### 7.7.4 Mean and Variance of a Binomial Distribution\n",
    "\n",
    "$$\\mu = np$$\n",
    "$$\\sigma^2 = np(1-p)$$\n",
    "$$\\sigma = \\sqrt{np(1-p)}$$\n",
    "\n",
    "## 7.8 Poisson Distribution\n",
    "\n",
    "Like the binomial random variable, the Poisson random variable is the number of occurrences of events, which we’ll continue to call successes. The difference between the two random variables is that a binomial random variable is the number of successes in a set number of trials, whereas a Poisson random variable is the number of successes in an interval of time or specific region of space.\n",
    "\n",
    "- The number of successes that occur in any interval is independent of the number of successes that occur in any other interval.\n",
    "- The probability of a success in an interval is the same for all equal-size intervals.\n",
    "- The probability of a success in an interval is proportional to the size of the interval.\n",
    "- The probability of more than one success in an interval approaches 0 as the interval becomes smaller.\n",
    "\n",
    "The probability that a Poisson random variable assumes a value of x in a specific interval is\n",
    "\n",
    "$$p(x) = \\frac{e^{-\\mu}\\mu^x}{x!}$$\n",
    "\n",
    "the variance of a Poisson random variable is equal to its mean; that is\n",
    "\n",
    "$$\\sigma^2 = \\mu$$\n",
    "\n",
    "$$p(X \\ge x) = 1 - p(X \\le (x-1))$$\n",
    "\n",
    "$$p(x) = p(X \\le x) - p(X \\le (x-1))$$\n",
    "\n",
    "# 8. Continuous Probability Distributions\n",
    "\n",
    "## 8.1 Uniform Distribution\n",
    "\n",
    "$$f(x) = \\frac{1}{b-a}, a \\le x \\le b$$\n",
    "\n",
    "## 8.2 Normal Distribution\n",
    "\n",
    "$$f(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{1}{2}(\\frac{x-\\mu}{\\sigma})^2}$$\n",
    "\n",
    "### 8.2.1 Calculating Normal Probabilities\n",
    "\n",
    "We standardize a random variable by subtracting its mean and dividing by its standard deviation. When the variable\n",
    "is normal, the transformed variable is called a standard normal random variable and denoted by Z; that is,\n",
    "\n",
    "$$Z = \\frac{X - \\mu}{\\sigma}$$\n",
    "\n",
    "## 8.3 Exponential Distribution\n",
    "\n",
    "$$f(x) = \\lambda e^{-\\lambda x}, x \\ge 0$$\n",
    "\n",
    "$$\\mu = \\sigma = \\frac{1}{\\lambda}$$\n",
    "\n",
    "$$p(X > x) = e^{-\\lambda x}$$\n",
    "\n",
    "$$p(X < x) = 1 - e^{-\\lambda x}$$\n",
    "\n",
    "$$p(x_{1} < X < x_{2}) = p(X < x_{2}) - p(X < x_{1}) = e^{-\\lambda x_{1}} - e^{-\\lambda x_{2}}$$\n",
    "\n",
    "\n",
    "## 8.4 Student t Distribution\n",
    "\n",
    "$$f(t)=\\frac{\\Gamma[(\\nu + 1)/2]}{\\sqrt{\\nu \\pi} \\Gamma (\\nu /2)}[1 + \\frac{t^2}{\\nu}]^{-(\\nu + 1)/2}$$\n",
    "\n",
    "where $\\nu$ (Greek letter nu) is the parameter of the Student t distribution called the **degrees of freedom**, and $\\Gamma$ is the gamma function.\n",
    "\n",
    "$$E(t) = 0$$\n",
    "\n",
    "$$V(t) = \\frac{\\nu}{\\nu - 2}, \\nu \\gt 2$$\n",
    "\n",
    "Student t distribution is similar to the standard normal distribution. Both are symmetrical about 0. We describe the Student t distribution as mound shaped, whereas the normal distribution is bell shaped. As $\\nu$ grows larger, the Student t distribution approaches the standard normal distribution.\n",
    "\n",
    "## 8.5 Chi-Squared Distribution\n",
    "\n",
    "$$f(\\chi^2) = \\frac{1}{\\Gamma(\\nu/2)} \\frac{1}{2^{\\nu/2}}(\\chi^2)^{(\\nu/2)-1}e^{-\\chi^2/2}$$\n",
    "\n",
    "$$E(\\chi^2) = \\nu$$\n",
    "\n",
    "$$V(\\chi^2) = 2\\nu$$\n",
    "\n",
    "## 8.6 F Distribution\n",
    "\n",
    "$$E(F) = \\frac{\\nu_{2}}{\\nu_{2} - 2}, \\nu_{2} \\gt 2$$\n",
    "\n",
    "$$V(F) = \\frac{2\\nu_{2}^2(\\nu_{1} + \\nu_{2} -2)}{\\nu_{1}(\\nu_{2}-1)^2(\\nu_{2} -4)}, \\nu_{2} \\gt 4$$\n",
    "\n",
    "$\\nu_{1}$ the numerator degrees of freedom and $\\nu_{2}$ the denominator degrees of freedom.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": false,
   "threshold": 6,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
